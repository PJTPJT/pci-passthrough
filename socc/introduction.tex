\section{Introduction}

% Introduction motivates the readers with the following aspects.
% - Bare-metal cloud or hardware as a service (HaaS)
% - Server support for HaaS
% - Network support for HaaS
% - Apply the virtualization to enhance the manageability of
%   servers in a HaaS
% - Single-VM virtualization requirements
%   - Direct device assignment for all PCIe devices
%   - Direct interrupt delivery
%   - Migration of bare-metal server
%   - VM introspection for the security and better visibility
\mycomment{
Infrastructure as a service (IaaS), which was popularized by AWS's EC2 service~\cite{ec2}, has evolved and morphed into multiple forms over the last decade.
The basic compute unit for IaaS began as a {\em virtual machine} (VM), which represents a slice of a physical machine carved out by a hardware-abstraction-layer, called the hypervisor.
A {\em container} is another basic compute unit, where a common operating system (OS) delimits the addressable system resources (or namespaces) for a group of processes and enforces usage limits.
A more recent IaaS compute unit is a {\em function}, which comes with a complete operating environment consisting of an OS and a middleware layer, and is created on demand.  
}

%Lately, to avoid multi-tenancy and security issues, a physical machine itself is 
%treated as a basic compute unit in {\em bare-metal cloud service}~\cite{bms-wiki}.
%or {\em hardware-as-a-service} (HaaS). 
%Infrastructure as a service (IaaS), which was popularized by AWS's EC2 service, has evolved and morphed into multiple forms over the last decade.
%In the beginning, the basic compute unit for IaaS was a {\em virtual machine}, which represents a slice of a physical machine carved out by a hardware-abstraction-layer hypervisor.
%Then the basic compute unit could also be a {\em container}, which is pre-configured with an operating system and corresponds to a piece of a physical machine delimited by that OS.
%%A more recent option for IaaS's basic compute unit is a {\em function}, which comes with a complete operating environment constsing of an OS and a middleware layer, and is created on demand.  
%Lately, even a physical machine could serve as the basic compute unit. This type of IaaS is known as {\em bare-metal cloud service} or {\em hardware as a service} (HaaS). 
%In the past three years, we have been developing a HaaS operating system called {\em ITRI HaaS OS} or \sna.  
%The focus of this paper is on \sna's virtualization support that enhances the manageability and serviceability required of a modern bare-metal cloud service. 


Conventional multi-tenant cloud services~\cite{ec2,azure,gcp} enable
users to rent virtual machines (VMs) or containers to scale 
up their IT infrastructure to the cloud. However, virtualization
introduces both performance overheads and security concerns
arising from co-located workloads of other users.
To address this concern, cloud operators 
such as  IBM SoftLayer~\cite{softlayer} and Oracle~\cite{oracle},
have begun to offer bare-metal cloud service, or Hardware-as-a-Service (HaaS),
%In the case of traditional multi-tenant IaaS, cloud operators own and manage 
%the physical machines, which are shared among multiple users.
%In contrast, bare-metal cloud operators, 
which allow users to rent dedicated  physical machines.
HaaS clouds enables users combine the benefits of 
scaling up their operations in the cloud with having dedicated 
hardware; users are assured stronger isolation than multi-tenant clouds and 
bare-metal performance for critical workloads 
such as high-performance computing, big data analytics, and AI.
%Other use cases of bare-metal cloud services include a preferred hypervisor 
%or OS that is not supported by cloud operators or special hardware for which virtualization 
%is not sufficiently mature, such as 
%GPUs, SoC-based micro-servers, and application-specific FPGA accelerators.

However, common management functions available on multi-tenant clouds,
such as live migration and introspection-based 
application performance management, are difficult to 
duplicate on HaaS servers, because HaaS providers typically 
do not install any software on these dedicated servers.

To address this manageability gap of existing HaaS platforms, 
we have been developing a HaaS management system, called 
%TODO: uncomment later
%\fullname (\sna) 
IHO,
with the goal of enhancing the manageability and serviceability 
of modern bare-metal cloud services.
The focus of this paper is on IHO's support for a 
specialized hypervisor, called the Single VM
hypervisor (\sna), that runs on each physical server and is optimized to run a single VM, called the 
HaaS VM\footnote{The \na could conceptually be an extension of a physical server's trusted BIOS.}.

During normal execution, the \na allows 
the HaaS VM to directly interact with physical I/O devices and processor hardware
without the hypervisor's intervention, 
as if it runs directly on a physical server with negligible performance overheads.
At the same time, the \na can provide the HaaS VM with 
manageability features of conventional clouds, such as 
live migration and VM introspection.

%Bare-metal cloud operators provide a user with a physical data center instance (PDCI), which is 
%composed of a set of physical machines connected in a way specified by the user. 
%In the past three years, we have been developing a HaaS operating system called 
%
%
%
%
%A HaaS user or tenant makes a HaaS service request to \na by specifying a PDCI, which consists of 
%The HaaS offerings from cloud operators such as IBM (SoftLayer) and Oracle provide a user a physical data center instance (PDCI), which is composed of a set of physical machines connected in a way specified by the user. HaaS users prefer physical machines to virtual machines primarily because they want to make the best of the underlying hardware resources for workloads that do not need the flexibility afforded by virtualization, such as HPC computation, big data analytics or AI training.
%Other HaaS use cases include that users have a preferred hypervisor or operating system which is not supported by cloud operators, and 
%that users need special hardware for which virtualization is not sufficiently mature, such as ARM SOC-based micro-server and GPU/FPGA cluster.
%
%In the case of IaaS, cloud operators own and manage the physical machines.
%In contrast, for HaaS, cloud operators own the physical machines but users manage them. 
%This way, HaaS users are still able to enjoy the multiplexing benefits of cloud computing that are due to sharing of hardware and facilities.
%A HaaS user or tenant makes a HaaS service request to \na by specifying a PDCI, which consists of 
%\begin{itemize} 
%\parskip 0mm
%\itemsep 0mm
%\item A set of physical servers, each with its CPU/memory/PCIe device specification, and configurations on the BIOS, and PCI devices,
%
%\item A set of storage volumes that exist in local or shared storage, and are attached to the servers,
%
%\item A set of IP subnets that describe how the servers are connected with one another and to the Internet, and  
%
%\item A set of public IP addresses to be bound to some of the servers facing the Internet, and their firewall policies. 
%
%\end{itemize}
%\na processes each PDCI request by first making corresponding allocations for server, network and storage resources, and 
%then setting up the PDCI's required network connectivity.  Because a HaaS operator cannot install any agent software on the physical servers rented out on a PDCI, the only way for \na to programmatically build a virtual network that meets a PDCI's IP subset specification is to leverage the VLAN and VXLAN capabilities in modern network switches and routers by properly configuring them according to the network connectivity specification.  
%Moreover, \na allows a HaaS tenant to {\em remotely} check, configure, and update the firmware on the physical servers, as well as install the desired operating systems and applications 
%on them, in a way that minimizes human errors and the adverse side effects that come with these errors. 
%Finally, \na enables a HaaS tenant to monitor the hardware status of the physical servers and the network traffic among them with full visibility, without revealing anything associated with other co-located tenants. 
%
%
%For the HaaS use case in which a tenant installs an operating system (Linux or Windows) rather than a 
%proprietary hypervisor on the physical servers of its PDCI, 
%

Unlike traditional hypervisors, which are designed to limit and control a VM's 
access to physical resources, \na is designed to maximize the HaaS VM's 
access to physical hardware while retaining the ability to live migrate the VM on demand.
Specifically, \na provides the following features for a HaaS VM. 
\begin{itemize} 
%\setlength\itemsep{-0.04in}
\parskip 0mm
\itemsep 0mm

\item {\bf Dedicated hardware resources for a HaaS VM:} \na provides a HaaS VM with 
dedicated physical CPU, memory, and other hardware resources such as 
local APIC timers, and passthrough PCIe I/O devices. 
A HaaS VM can interact with its hardware resources
directly for its normal execution without hypervisor intervention.


\item {\bf Direct delivery of all interrupts:}
Existing approaches~\cite{amit:2015,tu:2015}
only deliver PCIe device interrupts directly, i.e. without VM Exits, to a VM.
Besides direct PCIe interrupts, \na also enables
a HaaS VM to directly receive
timer interrupts from local APIC and inter-processor interrupts (IPIs) 
between its virtual CPUs (VCPUs) via a novel use of VT-d 
posted-interrupt~\cite{postedinterrupt} mechanism.


\item {\bf Seamless live migration:}
\na provides on-demand live migration of a HaaS VM having direct access to 
physical network devices and local APIC timers. 
%through coordinated switching to para-virtual I/O during migration.
\na seamlessly disables the HaaS VM's physical hardware access at the 
source machine before migration and 
re-establishes access at the destination after migration
with minimal disruption to the VM's liveness and performance.
Unlike existing live migration~\cite{vfio-live-migration,blmvisor-journal,ondemand} approaches for VMs with pasthrough 
I/O access, \na does not require device-specific state capture and migration code 
nor does it require the hypervisor to trust the guest OS. 
%Yet \na matches the liveness and performance of traditional live migration.

\item {\bf Elimination of all major VM Exit overheads:}  during a HaaS VM's execution. 
Even with passthrough I/O support~\cite{intelvtd-paper,intelvtd-manual}, 
VM Exits can still lower the I/O throughput and increase CPU usage of the host.
\na includes mechanisms to systematically eliminate
these traditional hypervisor-induced overheads to match bare-metal I/O performance and CPU utilization.

\item {\bf Small footprint:} 
\sna's execution footprint is currently limited to one non-dedicated 
CPU core and its memory footprint to around 100MB of RAM, with room for further reductions.
%TODO: Confirm with Kevin that CPU0 can also be used by the HaaS VM.
A small HaaS agent in the guest runs as a self-contained kernel module
to enable/disable HaaS features of the VM and coordinate live migration with \sna.
Other than during startup and live migration, the \na is not involved in the
HaaS VM's normal execution and thus imposes negligible performance overhead at run time.  

\end{itemize}

%With such a hypervisor installed on each physical server, \na can monitor each 
%server's internal user activities using VM introspection, and seamlessly migrate the user state 
%on the server from one physical machine to another. 

The rest of this paper is organized as follows.
We first describe the design and implementation of \sna,
specifically the detailed description of the above features.
Next, we evaluate the performance of our \na prototype
on the Linux and KVM/QEMU platform.
Finally, we discuss related work followed by conclusions.

